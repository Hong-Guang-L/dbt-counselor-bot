# DBTæƒ…æ„Ÿå’¨è¯¢æœºå™¨äºº

åŸºäº Qwen3-1.7B çš„ DBTï¼ˆè¾©è¯è¡Œä¸ºç–—æ³•ï¼‰æƒ…æ„Ÿå’¨è¯¢æœºå™¨äººï¼Œä½¿ç”¨ LoRA å¾®è°ƒè®­ç»ƒï¼Œä¸“ä¸ºç©ºå·¢è€äººæä¾›å¿ƒç†æ”¯æŒã€‚

## ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [ç¬¬ä¸€æ­¥ï¼šå®‰è£… Python](#ç¬¬ä¸€æ­¥å®‰è£…-python)
- [ç¬¬äºŒæ­¥ï¼šåˆ›å»ºé¡¹ç›®ç¯å¢ƒ](#ç¬¬äºŒæ­¥åˆ›å»ºé¡¹ç›®ç¯å¢ƒ)
- [ç¬¬ä¸‰æ­¥ï¼šå®‰è£…ä¾èµ–](#ç¬¬ä¸‰æ­¥å®‰è£…ä¾èµ–)
- [ç¬¬å››æ­¥ï¼šä¸‹è½½åŸºç¡€æ¨¡å‹](#ç¬¬å››æ­¥ä¸‹è½½åŸºç¡€æ¨¡å‹)
- [ç¬¬äº”æ­¥ï¼šå¼€å§‹è®­ç»ƒ](#ç¬¬äº”æ­¥å¼€å§‹è®­ç»ƒ)
- [ç¬¬å…­æ­¥ï¼šåˆå¹¶æƒé‡](#ç¬¬å…­æ­¥åˆå¹¶æƒé‡)
- [ç¬¬ä¸ƒæ­¥ï¼šé‡åŒ–æ¨¡å‹](#ç¬¬ä¸ƒæ­¥é‡åŒ–æ¨¡å‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ç¯å¢ƒè¦æ±‚

| é…ç½® | æœ€ä½è¦æ±‚ |
|------|----------|
| GPU | NVIDIA RTX 3060 (12GBæ˜¾å­˜) æˆ–æ›´é«˜ |
| å†…å­˜ | 16 GB |
| ç¡¬ç›˜ | 30 GB å¯ç”¨ç©ºé—´ |
| ç³»ç»Ÿ | Windows 10/11 æˆ– Linux |
| Python | 3.10 |

> âš ï¸ **æ³¨æ„**ï¼šå¿…é¡»æœ‰ NVIDIA æ˜¾å¡ï¼ŒAMD æ˜¾å¡æˆ–æ ¸æ˜¾æ— æ³•è®­ç»ƒã€‚

---

## ç¬¬ä¸€æ­¥ï¼šå®‰è£… Python

### Windows

1. ä¸‹è½½ Python 3.10ï¼šhttps://www.python.org/downloads/release/python-31011/
2. é€‰æ‹© **Windows installer (64-bit)**
3. è¿è¡Œå®‰è£…ç¨‹åºï¼Œ**å‹¾é€‰ "Add Python to PATH"**
4. ç‚¹å‡» Install Now

### éªŒè¯å®‰è£…

æ‰“å¼€å‘½ä»¤æç¤ºç¬¦ï¼ˆWin+R è¾“å…¥ cmdï¼‰ï¼Œè¾“å…¥ï¼š

```bash
python --version
```

æ˜¾ç¤º `Python 3.10.x` å³æˆåŠŸã€‚

---

## ç¬¬äºŒæ­¥ï¼šåˆ›å»ºé¡¹ç›®ç¯å¢ƒ

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Hong-Guang-L/dbt-counselor-bot.git
cd dbt-counselor-bot
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
python -m venv .venv
```

### 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

**Windowsï¼š**
```bash
.venv\Scripts\activate
```

**Linux/Macï¼š**
```bash
source .venv/bin/activate
```

æ¿€æ´»æˆåŠŸåï¼Œå‘½ä»¤è¡Œå‰é¢ä¼šæ˜¾ç¤º `(.venv)`ã€‚

---

## ç¬¬ä¸‰æ­¥ï¼šå®‰è£…ä¾èµ–

### 1. å®‰è£… PyTorchï¼ˆCUDA ç‰ˆæœ¬ï¼‰

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 2. éªŒè¯ CUDA

```bash
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0)}')"
```

æ˜¾ç¤ºä½ çš„æ˜¾å¡åç§°å³æˆåŠŸã€‚

### 3. å®‰è£…å…¶ä»–ä¾èµ–

```bash
pip install -r requirements.txt
```

---

## ç¬¬å››æ­¥ï¼šä¸‹è½½åŸºç¡€æ¨¡å‹

æˆ‘ä»¬ä½¿ç”¨ ModelScope ä¸‹è½½ Qwen3-1.7B æ¨¡å‹ï¼ˆå›½å†…é€Ÿåº¦å¿«ï¼‰ï¼š

```bash
pip install modelscope
```

ç„¶åè¿è¡Œï¼š

```bash
python -c "from modelscope import snapshot_download; snapshot_download('Qwen/Qwen3-1.7B', cache_dir='./models')"
```

ä¸‹è½½å®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åœ¨ `models/Qwen/Qwen3-1.7B/` ç›®å½•ã€‚

> ğŸ’¡ æ¨¡å‹çº¦ 3.4 GBï¼Œä¸‹è½½éœ€è¦å‡ åˆ†é’Ÿã€‚

---

## ç¬¬äº”æ­¥ï¼šå¼€å§‹è®­ç»ƒ

### 1. æ£€æŸ¥æ•°æ®é›†

é¡¹ç›®å·²åŒ…å«è®­ç»ƒæ•°æ® `datasets/train_final.json`ï¼Œæ— éœ€é¢å¤–å‡†å¤‡ã€‚

### 2. å¼€å§‹è®­ç»ƒ

```bash
llamafactory-cli train train.yaml
```

### 3. ç­‰å¾…è®­ç»ƒå®Œæˆ

è®­ç»ƒè¿‡ç¨‹ç¤ºä¾‹ï¼š

```
{'loss': 2.3456, 'learning_rate': 1e-4, 'epoch': 0.1}
{'loss': 1.8765, 'learning_rate': 9.5e-5, 'epoch': 0.2}
{'loss': 1.2345, 'learning_rate': 8e-5, 'epoch': 0.3}
...
```

è®­ç»ƒæ—¶é—´çº¦ 1-3 å°æ—¶ï¼ˆå–å†³äº GPU æ€§èƒ½ï¼‰ã€‚

### 4. è®­ç»ƒè¾“å‡º

è®­ç»ƒå®Œæˆåï¼ŒLoRA æƒé‡ä¿å­˜åœ¨ `output/qwen3_dbt_lora/` ç›®å½•ã€‚

---

## ç¬¬å…­æ­¥ï¼šåˆå¹¶æƒé‡

å°† LoRA æƒé‡ä¸åŸºç¡€æ¨¡å‹åˆå¹¶ï¼š

```bash
llamafactory-cli export merge.yaml
```

åˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨ `output/qwen3_dbt_merged/` ç›®å½•ã€‚

---

## ç¬¬ä¸ƒæ­¥ï¼šé‡åŒ–æ¨¡å‹

é‡åŒ–å¯ä»¥å¤§å¹…å‡å°æ¨¡å‹ä½“ç§¯ï¼ˆä» 3.4GB åˆ° 1.2GBï¼‰ã€‚

### 1. ä¸‹è½½ llama.cpp

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
```

### 2. ç¼–è¯‘ llama.cpp

**Windowsï¼ˆéœ€è¦å…ˆå®‰è£… Visual Studio Build Toolsï¼‰ï¼š**

```bash
mkdir build
cd build
cmake ..
cmake --build . --config Release
```

> ğŸ“¥ Visual Studio Build Tools ä¸‹è½½ï¼šhttps://visualstudio.microsoft.com/visual-cpp-build-tools/
> 
> å®‰è£…æ—¶å‹¾é€‰ "Desktop development with C++"

**Linuxï¼š**

```bash
make
```

### 3. è½¬æ¢ä¸º GGUF æ ¼å¼

```bash
python convert_hf_to_gguf.py ../output/qwen3_dbt_merged --outfile dbt-counselor-f16.gguf --outtype f16
```

### 4. é‡åŒ–

```bash
llama-quantize dbt-counselor-f16.gguf dbt-counselor-q4_k_m.gguf Q4_K_M
```

### 5. å®Œæˆï¼

é‡åŒ–åçš„æ¨¡å‹ `dbt-counselor-q4_k_m.gguf` çº¦ 1.2 GBï¼Œå¯ä»¥éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ã€‚

---

## å¸¸è§é—®é¢˜

### Q: CUDA æ˜¾ç¤ºä¸å¯ç”¨ï¼Ÿ

**æ£€æŸ¥æ­¥éª¤ï¼š**

1. ç¡®è®¤æœ‰ NVIDIA æ˜¾å¡
2. å®‰è£… NVIDIA é©±åŠ¨ï¼šhttps://www.nvidia.com/Download/index.aspx
3. å®‰è£… CUDA Toolkit 12.1ï¼šhttps://developer.nvidia.com/cuda-12-1-0-download-archive

### Q: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä¿®æ”¹ `train.yaml`ï¼š

```yaml
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
gradient_checkpointing: true
```

### Q: Windows ç¼–è¯‘ llama.cpp å¤±è´¥ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**

1. å®‰è£… [Visual Studio Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
2. å®‰è£…æ—¶å‹¾é€‰ "Desktop development with C++"
3. å®‰è£… [CMake](https://cmake.org/download/)
4. é‡å¯ç”µè„‘åé‡è¯•

### Q: ä¸‹è½½æ¨¡å‹å¤ªæ…¢ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š** ä½¿ç”¨ ModelScope è€Œä¸æ˜¯ HuggingFaceï¼ˆå·²åœ¨ä¸Šæ–‡ä½¿ç”¨ï¼‰ã€‚

---

## é¡¹ç›®ç»“æ„

```
dbt-counselor-bot/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ train_final.json      # è®­ç»ƒæ•°æ®é›†
â”œâ”€â”€ models/
â”‚   â””â”€â”€ Qwen/Qwen3-1.7B/      # åŸºç¡€æ¨¡å‹ï¼ˆéœ€ä¸‹è½½ï¼‰
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ qwen3_dbt_lora/       # LoRA æƒé‡
â”‚   â”œâ”€â”€ qwen3_dbt_merged/     # åˆå¹¶åæ¨¡å‹
â”‚   â””â”€â”€ Modelfile            # Ollama é…ç½®
â”œâ”€â”€ train.yaml               # è®­ç»ƒé…ç½®
â”œâ”€â”€ merge.yaml               # åˆå¹¶é…ç½®
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md
```

---

## è‡´è°¢

- [Qwen](https://github.com/QwenLM/Qwen) - åŸºç¡€æ¨¡å‹
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) - è®­ç»ƒæ¡†æ¶
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - é‡åŒ–å·¥å…·

---

## ç‰ˆæƒ

ç‰ˆæƒæ‰€æœ‰ Â© Hong-Guang-L | MIT License
